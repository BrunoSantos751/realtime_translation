# üéôÔ∏è Realtime Translation

Ferramenta de transcri√ß√£o e tradu√ß√£o em tempo real do √°udio do sistema (loopback), usando **OpenAI Whisper** para reconhecimento de fala. Captura o que est√° sendo reproduzido pelo computador e transcreve o conte√∫do diretamente no terminal ‚Äî com baix√≠ssima lat√™ncia.

---

## ‚ú® Funcionalidades Atuais

- **Captura de √°udio via Loopback (WASAPI)** ‚Äî captura tudo que sai pelo dispositivo de sa√≠da padr√£o do Windows, sem necessidade de microfone.
- **Buffer cont√≠nuo (Rolling Buffer)** ‚Äî gerencia ativamente o fluxo de √°udio, evitando ac√∫mulo e lat√™ncia progressiva.
- **Pr√©-processamento de √°udio** ‚Äî converte para `float32`, mixagem stereo‚Üímono e reamostragem para 16 kHz (padr√£o do Whisper).
- **VAD simples (Voice Activity Detection)** ‚Äî ignora sil√™ncio com base em limiar de energia RMS, evitando transcri√ß√µes vazias.
- **Transcri√ß√£o via OpenAI Whisper** ‚Äî suporte a m√∫ltiplos modelos (`tiny`, `base`, `small`, `medium`, `large`) com acelera√ß√£o GPU instant√¢nea via CUDA.
- **Tradu√ß√£o Offline Incremental** ‚Äî uso do **Argos Translate** para converter texto de Ingl√™s para Portugu√™s, analisando apenas o delta das palavras novas, evitando repeti√ß√£o de texto j√° traduzido.
- **Captura em thread separada** ‚Äî o processamento principal n√£o bloqueia a captura de √°udio.

---

## üóÇÔ∏è Estrutura do Projeto

```
realtime_translation/
‚îú‚îÄ‚îÄ main.py                  # Ponto de entrada da aplica√ß√£o
‚îú‚îÄ‚îÄ requirements.txt         # Depend√™ncias do projeto
‚îÇ
‚îú‚îÄ‚îÄ audio/
‚îÇ   ‚îú‚îÄ‚îÄ capture.py           # Captura de √°udio loopback (WASAPI) com buffer circular
‚îÇ   ‚îî‚îÄ‚îÄ preprocess.py        # Convers√£o, mixagem, reamostragem e VAD
‚îÇ
‚îú‚îÄ‚îÄ speech/
‚îÇ   ‚îî‚îÄ‚îÄ whisper_engine.py    # Wrapper do OpenAI Whisper para transcri√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îî‚îÄ‚îÄ rolling_buffer.py    # Buffer cont√≠nuo para evitar lat√™ncia cumulativa
‚îú‚îÄ‚îÄ translation/
‚îÇ   ‚îî‚îÄ‚îÄ translator.py        # M√≥dulo de tradu√ß√£o offline com Argos Translate
‚îú‚îÄ‚îÄ overlay/                 # (futuro) Overlay na tela
‚îÇ
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ test_audio_buffer.py      # Testes do buffer de √°udio
    ‚îî‚îÄ‚îÄ test_resample_speed.py    # Benchmark de reamostragem
```

---

## üöÄ Como Usar

### Pr√©-requisitos

- Windows 10/11
- Python 3.10+
- PyTorch instalado (com suporte a CUDA opcional, para GPU)

### Instala√ß√£o

```bash
# Clone o reposit√≥rio
git clone https://github.com/BrunoSantos751/realtime_translation.git
cd realtime_translation

# Instale as depend√™ncias
pip install -r requirements.txt
```

> **Nota:** O `openai-whisper` requer `ffmpeg` instalado no sistema. Instale via [ffmpeg.org](https://ffmpeg.org/download.html) ou com `winget install ffmpeg`.

### Executando

```bash
python main.py
```

O programa ir√°:
1. Detectar automaticamente o dispositivo de sa√≠da padr√£o (loopback).
2. Carregar o modelo Whisper (`small` por padr√£o) e o modelo de tradu√ß√£o do Argos Translate (baixa automaticamente no primeiro uso).
3. Iniciar a captura de √°udio, executando VAD, transcri√ß√£o em Ingl√™s e tradu√ß√£o inteligente para o Portugu√™s em tempo real no terminal.

Pressione `Ctrl+C` para encerrar.

### Configura√ß√£o

No `main.py`, voc√™ pode ajustar:

| Par√¢metro | Onde | Descri√ß√£o |
|---|---|---|
| `model_name` | `WhisperTranscriber(model_name=...)` | Modelo Whisper: `tiny`, `base`, `small`, `medium`, `large` |
| `chunk_duration` | `capturer.start_capture(...)` | Dura√ß√£o da captura r√°pida de cada chunk em segundos (ex: `0.4s`) |
| `language` | `transcriber.transcribe(..., language=...)` | Idioma de *origem* capturado no √°udio, ex: `"en"` |
| `window_size` | `RollingAudioBuffer(window_size=...)` | Tamanho da janela enviada ao Whisper (padr√£o: `2.5s`) |
| `from_code` / `to_code` | `TranslationEngine(from_code=..., to_code=...)` | Idiomas de tradu√ß√£o, do Argos Translate (ex: `"en"` para `"pt"`) |

---

## üì¶ Depend√™ncias

| Pacote | Fun√ß√£o |
|---|---|
| `pyaudiowpatch` | Captura de √°udio loopback via WASAPI no Windows |
| `openai-whisper` | Modelo de reconhecimento de fala |
| `torch` | Backend para execu√ß√£o do Whisper (CPU ou GPU) |
| `numpy` | Manipula√ß√£o de arrays de √°udio |
| `scipy` | Reamostragem de √°udio |
| `argostranslate` | Tradu√ß√£o local offline |

---

## üó∫Ô∏è Roadmap

- [x] **M√≥dulo de Tradu√ß√£o offline** ‚Äî traduzindo transcri√ß√µes com algoritmos anti-repeti√ß√£o usando Argos Translate.
- [ ] **Overlay na Tela** ‚Äî exibi√ß√£o do texto transcrito/traduzido como uma janela flutuante transparente sobre outras aplica√ß√µes (ideal para lives, videoconfer√™ncias e conte√∫do em l√≠ngua estrangeira).
- [ ] **Sele√ß√£o de idioma de origem e destino** via interface ou configura√ß√£o.
- [ ] **Interface gr√°fica (GUI)** ‚Äî controles para iniciar/parar, selecionar modelo e idioma.
- [ ] **Hist√≥rico de transcri√ß√µes** ‚Äî salvar transcri√ß√µes em arquivo de texto.

